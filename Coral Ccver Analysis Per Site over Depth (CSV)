import os
import csv
import numpy as np
import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox, ttk


# Function to extract coral cover data
def extract_coral_cover(file_path):
    print(f"Processing file: {file_path}")
    total_points = 75
    nc_count = 0  # Count of "NC" points (non-coral)

    # Open and read the CSV data
    with open(file_path, 'r') as file:
        reader = csv.reader(file)

        # Iterate through the rows to find the "NC" points
        for row in reader:
            if len(row) > 1:
                annotation = row[1].strip()  # The second column contains the annotation
                if annotation == "NC":
                    nc_count += 1

    # Calculate the number of coral points
    coral_points = total_points - nc_count
    percent_coral_cover = (coral_points / total_points) * 100
    return percent_coral_cover


# Function to analyze selected folder and files
def analyze_folder():
    folder_path = filedialog.askdirectory()  # Let the user select a folder
    if folder_path:
        print(f"Selected folder: {folder_path}")
        site_summary, transect_summary, depth_summary, island_wide_depth_summary = analyze_data(folder_path)

        # Display results in the text area
        result_text.delete(1.0, tk.END)  # Clear previous results
        result_text.insert(tk.END, "Overall Coral Cover Averages by Site:\n")
        for site, avg, std_error, n in site_summary:
            result_text.insert(tk.END, f"Site: {site}, Avg Cover: {avg:.2f}, Std Error: {std_error:.2f}, n={n}\n")

        result_text.insert(tk.END, "\nCoral Cover Averages by Transect:\n")
        for site, transect, avg, std_error, n in transect_summary:
            result_text.insert(tk.END, f"Site: {site}, Transect: {transect}, Avg Cover: {avg:.2f}, Std Error: {std_error:.2f}, n={n}\n")

        result_text.insert(tk.END, "\nCoral Cover Averages by Depth Per Site:\n")
        for site, depth, avg, std_error, n in depth_summary:
            result_text.insert(tk.END, f"Site: {site}, Depth: {depth}, Avg Cover: {avg:.2f}, Std Error: {std_error:.2f}, n={n}\n")

        result_text.insert(tk.END, "\nIsland-Wide Depth Averages:\n")
        for depth, avg, std_error, n in island_wide_depth_summary:
            result_text.insert(tk.END, f"Depth: {depth}, Island-Wide Avg Cover: {avg:.2f}, Std Error: {std_error:.2f}, n={n}\n")

        # Ask where to save the CSV file
        save_csv(site_summary, transect_summary, depth_summary, island_wide_depth_summary)


# Function to select a folder and calculate coral cover
def analyze_data(folder_path):
    coral_data = {}
    transect_data = {}

    print(f"Analyzing data in folder: {folder_path}")

    # Traverse the folder structure
    for root, dirs, files in os.walk(folder_path):
        for file_name in files:
            if file_name.endswith('.cpc'):
                file_path = os.path.join(root, file_name)
                coral_cover = extract_coral_cover(file_path)

                # Extract site and transect information from the folder name
                relative_path = os.path.relpath(root, folder_path)
                site = relative_path.split(os.sep)[0]
                transect = relative_path.split(os.sep)[1]  # Extract transect (e.g., 'Trans 1 - 20m')

                if site not in coral_data:
                    coral_data[site] = {}
                if transect not in coral_data[site]:
                    coral_data[site][transect] = []
                coral_data[site][transect].append(coral_cover)

    # Summarize the overall data by site (averaging all transects)
    site_summary = []
    for site, transect_data in coral_data.items():
        all_cover_data = [item for sublist in transect_data.values() for item in sublist]
        avg_cover = np.mean(all_cover_data)
        std_error = np.std(all_cover_data) / np.sqrt(len(all_cover_data))
        n = len(all_cover_data)
        site_summary.append([site, avg_cover, std_error, n])

    # Summarize the data by transect
    transect_summary = []
    for site, transect_data in coral_data.items():
        for transect, cover_data in transect_data.items():
            avg_cover = np.mean(cover_data)
            std_error = np.std(cover_data) / np.sqrt(len(cover_data))
            n = len(cover_data)
            transect_summary.append([site, transect, avg_cover, std_error, n])

    # Summarize the data by depth within each site
    depth_summary = []
    for site, transect_data in coral_data.items():
        depth_data_per_site = {}

        for transect, cover_data in transect_data.items():
            depth = transect.split(' - ')[-1]  # Extract the depth part of the transect (e.g., '20m')
            if "m" in depth:
                depth = depth.replace("m", "")
            if depth not in depth_data_per_site:
                depth_data_per_site[depth] = []
            depth_data_per_site[depth].extend(cover_data)  # Add data for this depth across transects

        # Calculate the summary for each depth within this site
        for depth, cover_data in depth_data_per_site.items():
            avg_cover = np.mean(cover_data)
            std_error = np.std(cover_data) / np.sqrt(len(cover_data))
            n = len(cover_data)
            depth_summary.append([site, int(depth), avg_cover, std_error, n])  # Convert depth to int for proper sorting

    # Sort depth_summary from shallowest to deepest
    depth_summary.sort(key=lambda x: (x[0], x[1]))  # Sort by site first, then depth

    # Calculate island-wide depth averages (aggregate across sites)
    island_wide_depth_summary = []
    island_depth_data = {}

    # Traverse the transect data again to collect depth information
    for site, transect_data in coral_data.items():
        for transect, cover_data in transect_data.items():
            depth = transect.split(' - ')[-1]  # Extract the depth part of the transect (e.g., '20m')
            if "m" in depth:
                depth = depth.replace("m", "")
            if depth not in island_depth_data:
                island_depth_data[depth] = []
            island_depth_data[depth].extend(cover_data)

    # Calculate island-wide averages for each depth
    for depth, cover_data in island_depth_data.items():
        avg_cover = np.mean(cover_data)
        std_error = np.std(cover_data) / np.sqrt(len(cover_data))
        n = len(cover_data)
        island_wide_depth_summary.append([int(depth), avg_cover, std_error, n])  # Convert depth to int for sorting

    # Sort island-wide depth summary from shallowest to deepest
    island_wide_depth_summary.sort(key=lambda x: x[0])  # Sort by the first column (depth)

    return site_summary, transect_summary, depth_summary, island_wide_depth_summary


# Function to save results as a CSV
def save_csv(site_summary, transect_summary, depth_summary, island_wide_depth_summary):
    # Prompt user for a base file path (without .csv)
    file_path = filedialog.asksaveasfilename(defaultextension=".csv", filetypes=[("CSV files", "*.csv")])

    if file_path:
        print(f"Saving results to {file_path}")

        # Save the site-level averages as a CSV file
        site_csv_path = file_path.replace(".csv", "_site.csv")
        df_site = pd.DataFrame(site_summary, columns=["Site", "Average Coral Cover", "Standard Error", "n"])
        df_site.to_csv(site_csv_path, index=False)

        # Save the transect-level averages as a CSV file
        transect_csv_path = file_path.replace(".csv", "_transect.csv")
        df_transect = pd.DataFrame(transect_summary,
                                   columns=["Site", "Transect", "Average Coral Cover", "Standard Error", "n"])
        df_transect.to_csv(transect_csv_path, index=False)

        # Save the depth-level averages per site as a CSV file
        depth_per_site_csv_path = file_path.replace(".csv", "_depth_per_site.csv")
        df_depth_per_site = pd.DataFrame(depth_summary,
                                         columns=["Site", "Depth", "Average Coral Cover", "Standard Error", "n"])
        df_depth_per_site.to_csv(depth_per_site_csv_path, index=False)

        # Save the island-wide depth averages as a CSV file
        island_wide_depth_csv_path = file_path.replace(".csv", "_island_wide_depth.csv")
        df_island_wide_depth = pd.DataFrame(island_wide_depth_summary,
                                            columns=["Depth", "Island-Wide Average Coral Cover", "Standard Error", "n"])
        df_island_wide_depth.to_csv(island_wide_depth_csv_path, index=False)

        print(
            f"Data saved to {site_csv_path}, {transect_csv_path}, {depth_per_site_csv_path}, and {island_wide_depth_csv_path}")
        messagebox.showinfo("Success",
                            f"Data saved to {site_csv_path}, {transect_csv_path}, {depth_per_site_csv_path}, and {island_wide_depth_csv_path}")


# GUI window setup
root = tk.Tk()
root.title("Coral Cover Analyzer")

# Folder selection button
select_button = ttk.Button(root, text="Select Folder and Analyze", command=analyze_folder)
select_button.pack(pady=10)

# Text area for displaying results
result_text = tk.Text(root, height=20, width=80)
result_text.pack(pady=10)

# Run the GUI loop
root.mainloop()
